{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "from astropy.table import Table, QTable, Column\n",
    "from os import listdir, rename\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def perform_Gaia_query(G_lim):\n",
    "    \"\"\"Perform a query from Gaia DR2.\n",
    "\n",
    "    The query will include all the stars brighter with G<G_lim that also have a 5-parameter\n",
    "    astrometric solution together with BP and RP measurements. Their astrometric parameters,\n",
    "    uncertainties and correlations together with G, BP and RP magnitudes are saved to a VOTable.\n",
    "    The name of the VOTable file is returned.\n",
    "    \"\"\"\n",
    "    from astroquery.gaia import Gaia\n",
    "\n",
    "    astrometry = ('ra', 'dec', 'parallax', 'pmra', 'pmdec')\n",
    "    columns_to_query = ''\n",
    "    # Add astrometric measurements, uncertanties and correlations to the columns to be queried\n",
    "    for i, col in enumerate(astrometry):\n",
    "        columns_to_query += col+', '\n",
    "        columns_to_query += col+'_error, '\n",
    "        for col2 in astrometry[i+1:]:\n",
    "            columns_to_query += col+'_'+col2+'_corr, '\n",
    "    # Make sure the magnitudes in the three bands are queried too\n",
    "    for band in ('g', 'bp', 'rp'):\n",
    "        columns_to_query += 'phot_'+band+'_mean_mag, '\n",
    "    # Remove the last comma\n",
    "    columns_to_query = columns_to_query[:-2]\n",
    "    job = Gaia.launch_job_async(f'SELECT {columns_to_query}\\\n",
    "                                 FROM gaiadr2.gaia_source\\\n",
    "                                 WHERE phot_g_mean_mag < {G_lim}\\\n",
    "                                     AND parallax IS NOT NULL\\\n",
    "                                     AND bp_rp IS NOT NULL\\\n",
    "                                 ;', dump_to_file=True)\n",
    "    return job.outputFile\n",
    "\n",
    "\n",
    "G_lim = 11\n",
    "filename = f'brighter_than_{G_lim}.vot'\n",
    "if filename not in listdir():\n",
    "    print('Performing a query from Gaia archive. This might take a while...')\n",
    "    rename(perform_Gaia_query(G_lim), filename)\n",
    "else:\n",
    "    print('Reading data from a stored file.')\n",
    "data = QTable.read(filename)\n",
    "# Astropy QTable has problems parsing the proper motion units, so we have to help it along.\n",
    "for col in data.columns:\n",
    "    if 'pm' in col and 'corr' not in col:\n",
    "        data[col] = np.array(data[col])*u.Unit(str(data[col].unit))\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_covariance_matrix(stars):\n",
    "    \"\"\"Create the covariance matrix of the astrometric parameters of input stars.\"\"\"\n",
    "    covariance = np.ones((len(stars), 5, 5))\n",
    "    astrometry = ('ra', 'dec', 'parallax', 'pmra', 'pmdec')\n",
    "    for i, col in enumerate(astrometry):\n",
    "        # This covariance matrix is set up as a numpy array, so we need to strip the units.\n",
    "        covariance[:, i, :] *= np.array(stars[col+'_error'])[:, np.newaxis]\n",
    "        covariance[:, :, i] *= np.array(stars[col+'_error'])[:, np.newaxis]\n",
    "        for j in range(i+1, 5):\n",
    "            covariance[:, i, j] *= np.array(stars[col+'_'+astrometry[j]+'_corr'])\n",
    "            covariance[:, j, i] = covariance[:, i, j]\n",
    "    return covariance\n",
    "\n",
    "\n",
    "def convert_icrs_to_gal(stars):\n",
    "    \"\"\"Convert coordinates from ICRS to the Galactic system.\"\"\"\n",
    "    from coordTransform import transformIcrsToGal\n",
    "    gal_params = ('l', 'b', 'pml', 'pmb')\n",
    "    coords = np.array(stars['ra', 'dec', 'parallax', 'pmra', 'pmdec']).view((float, 5))\n",
    "    covariance = construct_covariance_matrix(stars)\n",
    "    gal_coords, gal_uncerts, gal_covariance = transformIcrsToGal(coords, 0, EqC=covariance)\n",
    "    temp = QTable(gal_coords[:, np.array((0, 1, 3, 4))], names=gal_params)\n",
    "    stars.add_columns(temp.columns.values())\n",
    "    for i, name, unit, err_unit in zip((0, 1, 3, 4), gal_params,\n",
    "                                       (u.deg, u.deg, u.mas/u.yr, u.mas/u.yr),\n",
    "                                       (u.mas, u.mas, u.mas/u.yr, u.mas/u.yr)):\n",
    "        stars[name] *= unit\n",
    "        stars.add_column(Column(np.sqrt(gal_covariance[:, i, i])), name=name+'_error')\n",
    "        # Right ascension and declination are in deg, but their uncertanties in mas.\n",
    "        # We must ensure the same for galactic longitude and latitude.\n",
    "        stars[name+'_error'] *= err_unit\n",
    "    return stars\n",
    "\n",
    "\n",
    "# Don't compute the galactic coordinates if they are already computed.\n",
    "if 'b' not in data.columns:\n",
    "    data = convert_icrs_to_gal(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating Tmean, taumean and vmeans'''\n",
    "\n",
    "filters = [(data['parallax'] > 10*data['parallax_error']) &\n",
    "                    (data['phot_bp_mean_mag'].value - data['phot_rp_mean_mag'].value > i) &\n",
    "                    ((data['phot_bp_mean_mag'].value - data['phot_rp_mean_mag'].value) < i+0.1) for i in np.arange(-0.3,0.8,0.1)]\n",
    "F = [data[filters[i]] for i in range(len(filters))]\n",
    "N = [len(F[i]) for i in range(len(filters))]\n",
    "\n",
    "app = [np.reshape(F[i]['phot_g_mean_mag'].value,(1,len(F[i]))) for i in range(len(N))]\n",
    "p = [np.reshape(F[i]['parallax'].value,(1,len(F[i]))) for i in range(len(N))]\n",
    "parallax = [np.reshape(F[i]['parallax'],(1,N[i])) for i in range(len(N))]\n",
    "longitude = [F[i]['l'] for i in range(len(N))]\n",
    "latitude = [F[i]['b'] for i in range(len(N))]\n",
    "mu_l = [np.reshape(F[i]['pml'],(1,N[i])) for i in range(len(N))]\n",
    "mu_b = [np.reshape(F[i]['pmb'],(1,N[i])) for i in range(len(N))]\n",
    "r = [np.reshape(parallax[i].to(u.kpc, equivalencies=u.parallax()),(1,N[i])) for i in range(len(N))]\n",
    "K = 4.7405 *u.km * u.yr / u.s / u.kpc / u.mas\n",
    "\n",
    "l = [np.array([-np.sin(longitude[i]), np.cos(longitude[i]), np.zeros(len(F[i]))]) for i in range(len(N))]\n",
    "b = [np.array([-np.sin(latitude[i])*np.cos(longitude[i]), -np.sin(latitude[i])*np.sin(longitude[i]), np.cos(latitude[i])]) for i in range(len(N))]\n",
    "\n",
    "\n",
    "Tm = []\n",
    "taum = []\n",
    "v_m = []\n",
    "for j in range(len(N)):\n",
    "    t1 = (l[j]*K*mu_l[j])*r[j]\n",
    "    t2 = (b[j]*K*mu_b[j])*r[j]\n",
    "    tau = t1 + t2\n",
    "    Tmean = np.zeros((3,3))\n",
    "    for i in range(N[j]): #i = star\n",
    "        u_1 = np.reshape(np.array([np.cos(latitude[j][i])*np.cos(longitude[j][i]), np.cos(latitude[j][i])*np.sin(longitude[j][i]), np.sin(latitude[j][i])]), (1,3))\n",
    "        T = np.eye(3) - np.outer(u_1,np.transpose(u_1))\n",
    "        Tmean += T\n",
    "\n",
    "    Tmean /= N[j]\n",
    "    Tm.append(Tmean)\n",
    "    \n",
    "    taumean = tau.mean(axis=1)\n",
    "    taum.append(taumean)\n",
    "\n",
    "    v_avv = np.matmul(np.linalg.inv(Tmean),taumean)\n",
    "    v_m.append(v_avv)\n",
    "    print(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating B-matrix'''\n",
    "\n",
    "Bm = []\n",
    "for j in range(len(N)):\n",
    "    B = np.zeros((3,3))\n",
    "    for i in range(N[j]):    \n",
    "        u_1 = np.reshape([np.cos(latitude[j][i])*np.cos(longitude[j][i]), np.cos(latitude[j][i])*np.sin(longitude[j][i]), np.sin(latitude[j][i])], (1,3))\n",
    "        T = np.eye(3) - np.outer(u_1,np.transpose(u_1))\n",
    "\n",
    "        l_1 = np.array([-np.sin(longitude[j][i]), np.cos(longitude[j][i]), np.zeros(len(F[j]))[i]])\n",
    "        b_1 = np.array([-np.sin(latitude[j][i])*np.cos(longitude[j][i]), -np.sin(latitude[j][i])*np.sin(longitude[j][i]), np.cos(latitude[j][i])])\n",
    "\n",
    "        t1 = (l_1*K*mu_l[j][0][i])*r[j][0][i]\n",
    "        t2 = (b_1*K*mu_b[j][0][i])*r[j][0][i]\n",
    "        tau = t1 + t2\n",
    "\n",
    "        deltatau = tau - np.matmul(T,v_m[j])\n",
    "        B = B + np.outer(deltatau,np.transpose(deltatau))\n",
    "\n",
    "    B /= N[j]\n",
    "    Bm.append(B)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating D matrix, dispersion and non-redundant elements'''\n",
    "\n",
    "Dm = []\n",
    "disp = []\n",
    "dm = []\n",
    "for j in range(len(N)):  \n",
    "    D = np.zeros((3,3))*u.km**2/(u.s**2)\n",
    "    for i in range(3):\n",
    "        for k in range(3):\n",
    "            for m in range(3):\n",
    "                for n in range(3):\n",
    "                    if m <= n:\n",
    "                        D[m,n] += Bm[j][i,k]/(Tm[j][k,m]*Tm[j][i,n])\n",
    "\n",
    "    Dm.append(D)\n",
    "    dispersions = np.diag(D)\n",
    "    disp.append(dispersions)\n",
    "    d = D[D!=0]\n",
    "    dm.append(d)\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''First try'''\n",
    "Amean = []\n",
    "displist = []\n",
    "for i in range(len(N)):\n",
    "    T_11 = Tm[i][0,0]\n",
    "    T_12 = Tm[i][0,1]\n",
    "    T_13 = Tm[i][0,2]\n",
    "    T_21 = Tm[i][1,0]\n",
    "    T_22 = Tm[i][1,1]\n",
    "    T_23 = Tm[i][1,2]\n",
    "    T_31 = Tm[i][2,0]\n",
    "    T_32 = Tm[i][2,1]\n",
    "    T_33 = Tm[i][2,2]\n",
    "    A = np.array([[T_11*T_11, T_11*T_12 + T_12*T_11, T_11*T_13 + T_13*T_11, T_12*T_12, T_12*T_13 + T_13*T_12, T_13*T_13],\n",
    "                 [T_11*T_21, T_11*T_22 + T_12*T_21, T_11*T_23 + T_13*T_21, T_12*T_22, T_12*T_23 + T_13*T_22, T_13*T_23],\n",
    "                 [T_11*T_31, T_11*T_32 + T_12*T_31, T_11*T_33 + T_13*T_31, T_12*T_32, T_12*T_33 + T_13*T_32, T_13*T_33],\n",
    "                 [T_21*T_21, T_21*T_22 + T_22*T_21, T_21*T_23 + T_23*T_21, T_22*T_22, T_22*T_23 + T_23*T_22, T_23*T_23],\n",
    "                 [T_21*T_31, T_21*T_32 + T_22*T_31, T_21*T_33 + T_23*T_31, T_22*T_32, T_22*T_33 + T_23*T_32, T_23*T_33],\n",
    "                 [T_31*T_31, T_31*T_32 + T_32*T_31, T_31*T_33 + T_33*T_31, T_32*T_32, T_32*T_33 + T_33*T_32, T_33*T_33]])\n",
    "    B11 = Bm[i][0][0].value\n",
    "    B12 = Bm[i][0][1].value\n",
    "    B13 = Bm[i][0][2].value\n",
    "    B22 = Bm[i][1,1].value\n",
    "    B23 = Bm[i][1,2].value\n",
    "    B33 = Bm[i][2,2].value\n",
    "    \n",
    "    b = np.array([[B11,B12,B13,B22,B23,B33]])\n",
    "    Ainv = np.linalg.inv(A)\n",
    "    Am = Ainv.mean(axis = 0)\n",
    "    dispers = np.outer(Ainv,b)\n",
    "    displist.append(dispers)\n",
    "  \n",
    "    \n",
    "    \n",
    "disp_x = []\n",
    "disp_y = []\n",
    "disp_z = []\n",
    "Dlist = [] #Non-redunant elements\n",
    "\n",
    "for i in range(len(N)):\n",
    "    Dlist.append(displist[i][0])\n",
    "    disp_x.append(displist[i][0][0])\n",
    "    disp_y.append(displist[i][0][3])\n",
    "    disp_z.append(displist[i][0][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amean = []\n",
    "displist = []\n",
    "for i in range(len(N)):\n",
    "    T_11 = Tm[i][0,0]\n",
    "    T_12 = Tm[i][0,1]\n",
    "    T_13 = Tm[i][0,2]\n",
    "    T_21 = Tm[i][1,0]\n",
    "    T_22 = Tm[i][1,1]\n",
    "    T_23 = Tm[i][1,2]\n",
    "    T_31 = Tm[i][2,0]\n",
    "    T_32 = Tm[i][2,1]\n",
    "    T_33 = Tm[i][2,2]\n",
    "    A = np.array([[T_11*T_11, T_11*T_12 + T_12*T_11, T_11*T_13 + T_13*T_11, T_12*T_12, T_12*T_13 + T_13*T_12, T_13*T_13],\n",
    "                 [T_11*T_21, T_11*T_22 + T_12*T_21, T_11*T_23 + T_13*T_21, T_12*T_22, T_12*T_23 + T_13*T_22, T_13*T_23],\n",
    "                 [T_11*T_31, T_11*T_32 + T_12*T_31, T_11*T_33 + T_13*T_31, T_12*T_32, T_12*T_33 + T_13*T_32, T_13*T_33],\n",
    "                 [T_21*T_21, T_21*T_22 + T_22*T_21, T_21*T_23 + T_23*T_21, T_22*T_22, T_22*T_23 + T_23*T_22, T_23*T_23],\n",
    "                 [T_21*T_31, T_21*T_32 + T_22*T_31, T_21*T_33 + T_23*T_31, T_22*T_32, T_22*T_33 + T_23*T_32, T_23*T_33],\n",
    "                 [T_31*T_31, T_31*T_32 + T_32*T_31, T_31*T_33 + T_33*T_31, T_32*T_32, T_32*T_33 + T_33*T_32, T_33*T_33]])\n",
    "    B11 = Bm[i][0,0].value\n",
    "    B12 = Bm[i][0,1].value\n",
    "    B13 = Bm[i][0,2].value\n",
    "    B22 = Bm[i][1,1].value\n",
    "    B23 = Bm[i][1,2].value\n",
    "    B33 = Bm[i][2,2].value\n",
    "    \n",
    "    b = np.array([[B11,B12,B13,B22,B23,B33]])\n",
    "    print(T_11)\n",
    "    #bm = np.mean(b)\n",
    "    #print(A)\n",
    "    Ainv = np.linalg.inv(A)\n",
    "    Am = Ainv.mean(axis = 0)\n",
    "    dispers = np.outer(Ainv,b)\n",
    "    displist.append(dispers)\n",
    "  \n",
    "    \n",
    "    \n",
    "disp_x = []\n",
    "disp_y = []\n",
    "disp_z = []\n",
    "for i in range(len(N)):\n",
    "    print(displist[i][0])\n",
    "    disp_x.append(displist[i][0][0])\n",
    "    disp_y.append(displist[i][0][3])\n",
    "    disp_z.append(displist[i][0][5])\n",
    "  \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Amean = np.zeros((11,6,6))\n",
    "displist = []\n",
    "for i in range(len(N)):\n",
    "    T_11 = Tm[i][0,0]\n",
    "    T_12 = Tm[i][0,1]\n",
    "    T_13 = Tm[i][0,2]\n",
    "    T_21 = Tm[i][1,0]\n",
    "    T_22 = Tm[i][1,1]\n",
    "    T_23 = Tm[i][1,2]\n",
    "    T_31 = Tm[i][2,0]\n",
    "    T_32 = Tm[i][2,1]\n",
    "    T_33 = Tm[i][2,2]\n",
    "    A = np.array([[T_11*T_11, T_11*T_12 + T_12*T_11, T_11*T_13 + T_13*T_11, T_12*T_12, T_12*T_13 + T_13*T_12, T_13*T_13],\n",
    "                 [T_11*T_21, T_11*T_22 + T_12*T_21, T_11*T_23 + T_13*T_21, T_12*T_22, T_12*T_23 + T_13*T_22, T_13*T_23],\n",
    "                 [T_11*T_31, T_11*T_32 + T_12*T_31, T_11*T_33 + T_13*T_31, T_12*T_32, T_12*T_33 + T_13*T_32, T_13*T_33],\n",
    "                 [T_21*T_21, T_21*T_22 + T_22*T_21, T_21*T_23 + T_23*T_21, T_22*T_22, T_22*T_23 + T_23*T_22, T_23*T_23],\n",
    "                 [T_21*T_31, T_21*T_32 + T_22*T_31, T_21*T_33 + T_23*T_31, T_22*T_32, T_22*T_33 + T_23*T_32, T_23*T_33],\n",
    "                 [T_31*T_31, T_31*T_32 + T_32*T_31, T_31*T_33 + T_33*T_31, T_32*T_32, T_32*T_33 + T_33*T_32, T_33*T_33]])\n",
    "    B11 = Bm[j][0][0].value\n",
    "    B12 = Bm[j][0][1].value\n",
    "    B13 = Bm[j][0][2].value\n",
    "    B22 = Bm[j][1,1].value\n",
    "    B23 = Bm[j][1,2].value\n",
    "    B33 = Bm[j][2,2].value\n",
    "    \n",
    "    b = np.array([[B11,B12,B13,B22,B23,B33]])\n",
    "    Am = A.mean(axis = 1)\n",
    "    print(A.shape)\n",
    "    print(Am.shape)\n",
    "    #Ainv = np.linalg.inv(A)\n",
    "    #Amean.append(Ainv)\n",
    "    #Amean+= Ainv\n",
    "\n",
    "    \n",
    "#disp_x = []\n",
    "#disp_y = []\n",
    "#disp_z = []\n",
    "#for i in range(len(N)):\n",
    "#    disp_x.append(displist[i][0][0])\n",
    "#    disp_y.append(displist[i][0][3])\n",
    "#    disp_z.append(displist[i][0][5])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating maximum absolut magnitude and minimum parallax'''\n",
    "\n",
    "M_Gl = []\n",
    "index = []\n",
    "p_min = []\n",
    "G_min = []\n",
    "for i in range(len(N)):\n",
    "    M_G = app[i] + 5*np.log10(p[i]/100)\n",
    "    M_Gl.append(M_G)\n",
    "\n",
    "for i in range(len(N)):   \n",
    "    index = (app[i] == np.amax(app[i]))\n",
    "    p_min.append(parallax[i][0][index[0]])\n",
    "    G_min.append(M_Gl[i][0][index[0]])\n",
    "\n",
    "p_min,G_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate vertex deviations'''\n",
    "verticess = []\n",
    "for j in range(len(N)):\n",
    "    vert_d = 0.5*np.arctan((2*Dlist[j][1])/(Dlist[j][0] - Dlist[j][3]))\n",
    "    verticess.append(vert_d)\n",
    "verticess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate minimum distances in kpc??'''\n",
    "distlist = []\n",
    "for j in range(len(N)):\n",
    "    dists = np.amin(r[j])\n",
    "    distlist.append(dists)\n",
    "distlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculate mean colours'''\n",
    "\n",
    "bprp = [(F[i]['phot_bp_mean_mag']*u.mag - F[i]['phot_rp_mean_mag']*u.mag) for i in range(len(N))]\n",
    "cm = []\n",
    "for j in range(len(N)):\n",
    "    cm.append(np.mean(bprp[j]))   \n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Plotting'''\n",
    "\n",
    "colorinterval = [col for col in np.arange(-0.3,0.8,0.1)]\n",
    "ages = [1.26e8, 2.51e8, 5.01e8, 6.31e8, 7.94e8, 1e9, 1.26e9, 1.58e9, 2.51e9, 3.98e9, 1e10]\n",
    "meanages = []\n",
    "for i in ages:\n",
    "    meanages.append(i/2)\n",
    "u_av = [v_m[i][0].value for i in range(len(N))]\n",
    "v_av = [v_m[i][1].value for i in range(len(N))]\n",
    "w_av = [v_m[i][2].value for i in range(len(N))]\n",
    "\n",
    "disp_u = [disp[i][0].value for i in range(len(N))]\n",
    "disp_v = [disp[i][1].value for i in range(len(N))]\n",
    "disp_w = [disp[i][2].value for i in range(len(N))]\n",
    "\n",
    "plt.figure(1)\n",
    "plt.rcParams['font.size'] = 20\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.add_subplot(221)\n",
    "plt.title('Average velocity vs Colour')\n",
    "plt.xlabel(r'bp-rp', fontsize = 18)\n",
    "plt.ylabel('Avergae velocity [km/s]', fontsize = 18)\n",
    "plt.plot(colorinterval,u_av, '--', label = r'$\\langle u \\rangle$')\n",
    "plt.plot(colorinterval,v_av, '--', label = r'$\\langle v \\rangle$')\n",
    "plt.plot(colorinterval,w_av, '--', label = r'$\\langle w \\rangle$')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(222)\n",
    "plt.title('Average velocity vs mean age')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Mean age', fontsize = 18)\n",
    "plt.ylabel('Avergae velocity [km/s]', fontsize = 18)\n",
    "plt.plot(meanages,u_av, '--', label = r'$\\langle u \\rangle$')\n",
    "plt.plot(meanages,v_av, '--', label = r'$\\langle v \\rangle$')\n",
    "plt.plot(meanages,w_av, '--', label = r'$\\langle w \\rangle$')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.rcParams['font.size'] = 20\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "fig.add_subplot(221)\n",
    "plt.title('Velocity dispersions vs colour')\n",
    "plt.xlabel(r'bp-rp', fontsize = 18)\n",
    "plt.ylabel('Velocity dispersion [km/s]', fontsize = 18)\n",
    "plt.plot(colorinterval, disp_x, '--', label = r'$\\sigma^2_{\\rm{u}}$')\n",
    "plt.plot(colorinterval, disp_y, '--', label = r'$\\sigma^2_{\\rm{v}}$')\n",
    "plt.plot(colorinterval, disp_z, '--', label = r'$\\sigma^2_{\\rm{w}}$')\n",
    "plt.legend()\n",
    "\n",
    "fig.add_subplot(222)\n",
    "plt.title('Velocity dispersion vs mean age')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r'Mean age', fontsize = 18)\n",
    "plt.ylabel('Velocity dispersion [km/s]', fontsize = 18)\n",
    "plt.plot(meanages, disp_x, '--', label = r'$\\sigma^2_{\\rm{u}}$')\n",
    "plt.plot(meanages, disp_y, '--', label = r'$\\sigma^2_{\\rm{v}}$')\n",
    "plt.plot(meanages, disp_z, '--', label = r'$\\sigma^2_{\\rm{w}}$')\n",
    "plt.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculating ratios in comparison with epicycle theory'''\n",
    "\n",
    "ratios = []\n",
    "for i in range(len(N)):\n",
    "    rat = disp[i][1]/disp[i][0]\n",
    "    ratios.append(rat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Calculation with new dispersions'''\n",
    "Ratios = []\n",
    "\n",
    "for i in range(len(N)):\n",
    "    Ratios.append(disp_y[i]/disp_x[i])\n",
    "\n",
    "plt.plot(colorinterval,Ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "disp_u_sqrt = []\n",
    "disp_v_sqrt = []\n",
    "disp_w_sqrt = []\n",
    "disp_x_sqrt = []\n",
    "disp_y_sqrt = []\n",
    "disp_z_sqrt = []\n",
    "\n",
    "\n",
    "for i in range(len(N)):\n",
    "    disp_u_sqrt.append(np.sqrt(disp_u[i]))\n",
    "    disp_v_sqrt.append(np.sqrt(disp_v[i]))\n",
    "    disp_w_sqrt.append(np.sqrt(disp_w[i]))\n",
    "    disp_x_sqrt.append(np.sqrt(disp_x[i]))\n",
    "    disp_y_sqrt.append(np.sqrt(disp_y[i]))\n",
    "    disp_z_sqrt.append(np.sqrt(disp_z[i]))\n",
    "    \n",
    "a1 = np.polyfit(np.log10(meanages),np.log10(disp_x_sqrt),1)\n",
    "a2 = np.polyfit(np.log10(meanages),np.log10(disp_y_sqrt),1)\n",
    "a3 = np.polyfit(np.log10(meanages),np.log10(disp_z_sqrt),1)\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "#plt.xscale('linear')\n",
    "#plt.yscale('linear')\n",
    "#plt.plot(meanages,a1list)\n",
    "#plt.plot(meanages,a2list)\n",
    "#plt.plot(meanages,a3list)\n",
    "\n",
    "#sigmalist = []\n",
    "#for i in range(len(N)):\n",
    "#    sigma = np.sqrt(disp_x[i] + disp_y[i] + disp_z[i])\n",
    "#    sigmalist.append(sigma)\n",
    "plt.ylabel(r'$\\sigma$ [km/s]')\n",
    "plt.xlabel('Mean age')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.plot(meanages,disp_x_sqrt, 'o', label = r'$\\sigma_u$, $\\alpha$ = {}'.format(a1[0]))\n",
    "plt.plot(meanages,disp_y_sqrt, 'o', label = r'$\\sigma_v$, $\\alpha$ = {}'.format(a2[0]))\n",
    "plt.plot(meanages,disp_z_sqrt, 'o', label = r'$\\sigma_w$, $\\alpha$ = {}'.format(a3[0]))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "a1,a2,a3\n",
    "\n",
    "\n",
    "#plt.plot(meanages,disp_v_sqrt, 'o', label = r'$\\sigma_{\\rm{v}}$')\n",
    "#plt.plot(meanages,disp_w_sqrt, 'o', label = r'$\\sigma_{\\rm{w}}$')\n",
    "\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.xlabel(r'$\\sigma^2_{\\rm{u}}$')\n",
    "plt.ylabel('Average velocities [km/s]')\n",
    "plt.plot( disp_x,u_av, 'o', label = r'$\\langle \\vec{u} \\rangle$')\n",
    "plt.plot(disp_x,v_av, 'o')\n",
    "plt.plot(disp_x,w_av, 'o')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.xlabel(r'$bp-rp$')\n",
    "plt.ylabel(r'Vertex deviation $\\theta$ [rad]')\n",
    "plt.plot(colorinterval, verticess, label = r'$\\theta$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "G_max = []\n",
    "Gapp_max = []\n",
    "distlist = []\n",
    "for j in range(len(N)):    \n",
    "    M_Gl = []\n",
    "    for i in range(len(app)):\n",
    "        M_G = app[i] + 5*np.log10(p[i]/100)\n",
    "        M_Gl.append(M_G)\n",
    "    max_Mg = np.max(app[j])\n",
    "    \n",
    "    G_max.append(max_Mg)\n",
    "    Gapp_max.append(max_app)\n",
    "\n",
    "\n",
    "    #max_app = np.max(app[j])\n",
    "    #distance = 10**((max_app - max_Mg + 5)/5)\n",
    "    #distlist.append(distance)\n",
    "\n",
    "print(G_max)\n",
    "print(Gapp_max)\n",
    "print(distlist)\n",
    "'''\n",
    "x = [1,2,3,4,5,6,7,8,9,10,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
